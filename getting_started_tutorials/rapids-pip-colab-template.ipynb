{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nithi7518/Lost-and-Found/blob/main/getting_started_tutorials/rapids-pip-colab-template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scfLT2i0MLyD"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/rapidsai-community/showcase/blob/main/getting_started_tutorials/rapids-pip-colab-template.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Install RAPIDS into Colab\"/>\n",
        "</a>\n",
        "\n",
        "# RAPIDS cuDF is now already on your Colab instance!\n",
        "RAPIDS cuDF is preinstalled on Google Colab and instantly accelerates Pandas with zero code changes. [You can quickly get started with our tutorial notebook](https://nvda.ws/rapids-cudf). This notebook template is for users who want to utilize the full suite of the RAPIDS libraries for their workflows on Colab.  \n",
        "\n",
        "# Environment Sanity Check #\n",
        "\n",
        "Click the _Runtime_ dropdown at the top of the page, then _Change Runtime Type_ and confirm the instance type is _GPU_.\n",
        "\n",
        "You can check the output of `!nvidia-smi` to check which GPU you have.  Please uncomment the cell below if you'd like to do that.  Currently, RAPIDS runs on all available Colab GPU instances."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67T0090Jk2KL"
      },
      "source": [
        "# !nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_v33LnDVNo3"
      },
      "source": [
        "#Setup:\n",
        "This set up script:\n",
        "\n",
        "1. Checks to make sure that the GPU is RAPIDS compatible\n",
        "1. Pip Installs the RAPIDS' libraries, which are:\n",
        "  1. cuDF\n",
        "  1. cuML\n",
        "  1. cuGraph\n",
        "  1. cuSpatial\n",
        "  1. cuxFilter\n",
        "  1. cuCIM\n",
        "  1. xgboost\n",
        "\n",
        "# Controlling Which RAPIDS Version is Installed\n",
        "This line in the cell below, `!python rapidsai-csp-utils/colab/pip-install.py`, kicks off the RAPIDS installation script.  You can control the RAPIDS version installed by adding either `latest`, `nightlies` or the default/blank option.  Example:\n",
        "\n",
        "`!python rapidsai-csp-utils/colab/pip-install.py <option>`\n",
        "\n",
        "You can now tell the script to install:\n",
        "1. **RAPIDS + Colab Default Version**, by leaving the install script option blank (or giving an invalid option), adds the rest of the RAPIDS libraries to the RAPIDS cuDF library preinstalled on Colab.  **This is the default and recommended version.**  Example: `!python rapidsai-csp-utils/colab/pip-install.py`\n",
        "1. **Latest known working RAPIDS stable version**, by using the option `latest` upgrades all RAPIDS labraries to the latest working RAPIDS stable version.  Usually early access for future RAPIDS+Colab functionality - some functionality may not work, but can be same as the default version. Example: `!python rapidsai-csp-utils/colab/pip-install.py latest`\n",
        "1. **the current nightlies version**, by using the option, `nightlies`, installs current RAPIDS nightlies version.  For RAPIDS Developer use - **not recommended/untested**.  Example: `!python rapidsai-csp-utils/colab/pip-install.py nightlies`\n",
        "\n",
        "\n",
        "**This will complete in about 5-6 minutes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0C8IV5TQnjN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3eead9-fe6c-4563-e680-0b68cc791bd3"
      },
      "source": [
        "# This get the RAPIDS-Colab install files and test check your GPU.  Run this and the next cell only.\n",
        "# Please read the output of this cell.  If your Colab Instance is not RAPIDS compatible, it will warn you and give you remediation steps.\n",
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/pip-install.py\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'rapidsai-csp-utils'...\n",
            "remote: Enumerating objects: 490, done.\u001b[K\n",
            "remote: Counting objects: 100% (221/221), done.\u001b[K\n",
            "remote: Compressing objects: 100% (130/130), done.\u001b[K\n",
            "remote: Total 490 (delta 149), reused 124 (delta 91), pack-reused 269\u001b[K\n",
            "Receiving objects: 100% (490/490), 136.70 KiB | 6.21 MiB/s, done.\n",
            "Resolving deltas: 100% (251/251), done.\n",
            "Collecting pynvml\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 714.5 kB/s eta 0:00:00\n",
            "Installing collected packages: pynvml\n",
            "Successfully installed pynvml-11.5.0\n",
            "Installing the rest of the RAPIDS 24.4.* libraries\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Requirement already satisfied: cudf-cu12==24.4.* in /usr/local/lib/python3.10/dist-packages (24.4.1)\n",
            "Collecting cuml-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cuml-cu12/cuml_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1200.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 GB 1.1 MB/s eta 0:00:00\n",
            "Collecting cugraph-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cugraph-cu12/cugraph_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1429.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 GB 460.9 kB/s eta 0:00:00\n",
            "Collecting cuspatial-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cuspatial-cu12/cuspatial_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.8/137.8 MB 8.3 MB/s eta 0:00:00\n",
            "Collecting cuproj-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cuproj-cu12/cuproj_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (920 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 920.9/920.9 kB 61.9 MB/s eta 0:00:00\n",
            "Collecting cuxfilter-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cuxfilter-cu12/cuxfilter_cu12-24.4.1-py3-none-any.whl (83 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.5/83.5 kB 14.3 MB/s eta 0:00:00\n",
            "Collecting cucim-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cucim-cu12/cucim_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.8/5.8 MB 101.3 MB/s eta 0:00:00\n",
            "Collecting pylibraft-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/pylibraft-cu12/pylibraft_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (823.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.0/823.0 MB 1.7 MB/s eta 0:00:00\n",
            "Collecting raft-dask-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/raft-dask-cu12/raft_dask_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (170.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 170.1/170.1 MB 7.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (3.9.5)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (5.3.3)\n",
            "Requirement already satisfied: cuda-python<13.0a0,>=12.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (12.2.1)\n",
            "Requirement already satisfied: cupy-cuda12x>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (12.2.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (2023.6.0)\n",
            "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (0.58.1)\n",
            "Requirement already satisfied: numpy<2.0a0,>=1.23 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (1.25.2)\n",
            "Requirement already satisfied: nvtx>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (0.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (24.1)\n",
            "Requirement already satisfied: pandas<2.2.2dev0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (2.0.3)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (3.20.3)\n",
            "Requirement already satisfied: pynvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (0.2.4)\n",
            "Requirement already satisfied: pyarrow<15.0.0a0,>=14.0.1 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (14.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (13.7.1)\n",
            "Requirement already satisfied: rmm-cu12==24.4.* in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (24.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (4.12.2)\n",
            "Collecting dask-cuda==24.4.* (from cuml-cu12==24.4.*)\n",
            "  Downloading dask_cuda-24.4.0-py3-none-any.whl (126 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.6/126.6 kB 3.7 MB/s eta 0:00:00\n",
            "Collecting dask-cudf-cu12==24.4.* (from cuml-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/dask-cudf-cu12/dask_cudf_cu12-24.4.1-py3-none-any.whl (48 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.9/48.9 kB 7.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.4.*) (1.4.2)\n",
            "Collecting rapids-dask-dependency==24.4.* (from cuml-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/rapids-dask-dependency/rapids_dask_dependency-24.4.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.4.*) (1.11.4)\n",
            "Collecting treelite==4.1.2 (from cuml-cu12==24.4.*)\n",
            "  Downloading treelite-4.1.2-py3-none-manylinux2014_x86_64.whl (810 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 810.9/810.9 kB 9.6 MB/s eta 0:00:00\n",
            "Collecting pylibcugraph-cu12==24.4.* (from cugraph-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/pylibcugraph-cu12/pylibcugraph_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1430.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 GB 912.3 kB/s eta 0:00:00\n",
            "Collecting ucx-py-cu12==0.37.* (from cugraph-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/ucx-py-cu12/ucx_py_cu12-0.37.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.7/7.7 MB 104.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: geopandas>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from cuspatial-cu12==24.4.*) (0.13.2)\n",
            "Requirement already satisfied: bokeh>=3.1 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.4.*) (3.3.4)\n",
            "Collecting datashader>=0.15 (from cuxfilter-cu12==24.4.*)\n",
            "  Downloading datashader-0.16.2-py2.py3-none-any.whl (18.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.3/18.3 MB 53.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: holoviews>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.4.*) (1.17.1)\n",
            "Collecting jupyter-server-proxy (from cuxfilter-cu12==24.4.*)\n",
            "  Downloading jupyter_server_proxy-4.2.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: panel>=1.0 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.4.*) (1.3.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from cucim-cu12==24.4.*) (8.1.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from cucim-cu12==24.4.*) (0.4)\n",
            "Requirement already satisfied: scikit-image<0.23.0a0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from cucim-cu12==24.4.*) (0.19.3)\n",
            "Collecting pynvml<11.5,>=11.0.0 (from dask-cuda==24.4.*->cuml-cu12==24.4.*)\n",
            "  Downloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.0/47.0 kB 7.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: zict>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from dask-cuda==24.4.*->cuml-cu12==24.4.*) (3.0.0)\n",
            "Collecting dask==2024.1.1 (from rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*)\n",
            "  Downloading dask-2024.1.1-py3-none-any.whl (1.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 64.0 MB/s eta 0:00:00\n",
            "Collecting distributed==2024.1.1 (from rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*)\n",
            "  Downloading distributed-2024.1.1-py3-none-any.whl (1.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 64.5 MB/s eta 0:00:00\n",
            "Collecting dask-expr==0.4.0 (from rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*)\n",
            "  Downloading dask_expr-0.4.0-py3-none-any.whl (161 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 161.7/161.7 kB 23.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (2.2.1)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (7.2.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (3.1.4)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (1.0.8)\n",
            "Requirement already satisfied: psutil>=5.7.2 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (3.0.0)\n",
            "Requirement already satisfied: tornado>=6.0.4 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (6.3.3)\n",
            "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (2.0.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (4.0.3)\n",
            "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.4.*) (1.2.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.4.*) (9.4.0)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.4.*) (2024.6.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from cuda-python<13.0a0,>=12.0->cudf-cu12==24.4.*) (3.0.10)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x>=12.0.0->cudf-cu12==24.4.*) (0.8.2)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (3.1.0)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (1.0.0)\n",
            "Requirement already satisfied: param in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (2.1.0)\n",
            "Collecting pyct (from datashader>=0.15->cuxfilter-cu12==24.4.*)\n",
            "  Downloading pyct-0.5.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (2.31.0)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (2023.7.0)\n",
            "Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.11.0->cuspatial-cu12==24.4.*) (1.9.6)\n",
            "Requirement already satisfied: pyproj>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.11.0->cuspatial-cu12==24.4.*) (3.6.1)\n",
            "Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.11.0->cuspatial-cu12==24.4.*) (2.0.4)\n",
            "Requirement already satisfied: pyviz-comms>=0.7.4 in /usr/local/lib/python3.10/dist-packages (from holoviews>=1.16.0->cuxfilter-cu12==24.4.*) (3.0.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57->cudf-cu12==24.4.*) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu12==24.4.*) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu12==24.4.*) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu12==24.4.*) (2024.1)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (3.6)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (3.0.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (2.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (4.66.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (6.1.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.23.0a0,>=0.19.0->cucim-cu12==24.4.*) (3.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.23.0a0,>=0.19.0->cucim-cu12==24.4.*) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.23.0a0,>=0.19.0->cucim-cu12==24.4.*) (2024.6.18)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.23.0a0,>=0.19.0->cucim-cu12==24.4.*) (1.6.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp) (3.7)\n",
            "Requirement already satisfied: jupyter-server>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.24.0)\n",
            "Collecting simpervisor>=1.0.0 (from jupyter-server-proxy->cuxfilter-cu12==24.4.*)\n",
            "  Downloading simpervisor-1.0.0-py3-none-any.whl (8.3 kB)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-proxy->cuxfilter-cu12==24.4.*) (5.7.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->cudf-cu12==24.4.*) (2.16.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.11.0->cuspatial-cu12==24.4.*) (2024.6.2)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.11.0->cuspatial-cu12==24.4.*) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.11.0->cuspatial-cu12==24.4.*) (0.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.11.0->cuspatial-cu12==24.4.*) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (2.1.5)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (3.7.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (23.1.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (6.1.12)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (5.7.2)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (6.5.4)\n",
            "Requirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (5.10.4)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.20.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (24.0.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.18.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.8.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel>=1.0->cuxfilter-cu12==24.4.*) (0.1.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=1.0->cuxfilter-cu12==24.4.*) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel>=1.0->cuxfilter-cu12==24.4.*) (1.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->datashader>=0.15->cuxfilter-cu12==24.4.*) (3.3.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.2.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (3.19.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (4.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (4.12.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (4.19.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (21.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.18.1)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (2.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (2.22)\n",
            "Installing collected packages: simpervisor, pynvml, pyct, ucx-py-cu12, treelite, dask, pylibraft-cu12, distributed, dask-expr, cuproj-cu12, cucim-cu12, rapids-dask-dependency, pylibcugraph-cu12, datashader, cuspatial-cu12, dask-cudf-cu12, dask-cuda, raft-dask-cu12, cuml-cu12, cugraph-cu12, jupyter-server-proxy, cuxfilter-cu12\n",
            "  Attempting uninstall: pynvml\n",
            "    Found existing installation: pynvml 11.5.0\n",
            "    Uninstalling pynvml-11.5.0:\n",
            "      Successfully uninstalled pynvml-11.5.0\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2023.8.1\n",
            "    Uninstalling dask-2023.8.1:\n",
            "      Successfully uninstalled dask-2023.8.1\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2023.8.1\n",
            "    Uninstalling distributed-2023.8.1:\n",
            "      Successfully uninstalled distributed-2023.8.1\n",
            "Successfully installed cucim-cu12-24.4.0 cugraph-cu12-24.4.0 cuml-cu12-24.4.0 cuproj-cu12-24.4.0 cuspatial-cu12-24.4.0 cuxfilter-cu12-24.4.1 dask-2024.1.1 dask-cuda-24.4.0 dask-cudf-cu12-24.4.1 dask-expr-0.4.0 datashader-0.16.2 distributed-2024.1.1 jupyter-server-proxy-4.2.0 pyct-0.5.0 pylibcugraph-cu12-24.4.0 pylibraft-cu12-24.4.0 pynvml-11.4.1 raft-dask-cu12-24.4.0 rapids-dask-dependency-24.4.1 simpervisor-1.0.0 treelite-4.1.2 ucx-py-cu12-0.37.0\n",
            "\n",
            "        ***********************************************************************\n",
            "        The pip install of RAPIDS is complete.\n",
            "        \n",
            "        Please do not run any further installation from the conda based installation methods, as they may cause issues!\n",
            "        \n",
            "        Please ensure that you're pulling from the git repo to remain updated with the latest working install scripts.\n",
            "\n",
            "        Troubleshooting:\n",
            "            - If there is an installation failure, please check back on RAPIDSAI owned templates/notebooks to see how to update your personal files. \n",
            "            - If an installation failure persists when using the latest script, please make an issue on https://github.com/rapidsai-community/rapidsai-csp-utils\n",
            "        ***********************************************************************\n",
            "        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZJMJ6BulmMn"
      },
      "source": [
        "# RAPIDS is now installed on Colab.  \n",
        "You can copy your code into the cells below or use the below to validate your RAPIDS installation and version.  \n",
        "# Enjoy!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nLrk46BllED",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5fa6c7aa-2809-49ec-849a-986c113c6cc1"
      },
      "source": [
        "import cudf\n",
        "cudf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'25.02.01'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy\n",
        "cupy.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AnmtYjzvVTtv",
        "outputId": "7d616b33-fbff-43fc-91cc-875bd72ae550"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'13.3.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dlsyk9m9NN2K"
      },
      "source": [
        "# Next Steps #\n",
        "\n",
        "For an overview of how you can access and work with your own datasets in Colab, check out [this guide](https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92).\n",
        "\n",
        "For more RAPIDS examples, check out our RAPIDS notebooks repos:\n",
        "1. https://github.com/rapidsai/notebooks\n",
        "2. https://github.com/rapidsai/notebooks-contrib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1: Setup & Imports (RAPIDS Version)\n",
        "import cudf\n",
        "import cupy as cp\n",
        "import re\n",
        "\n",
        "from cuml.model_selection import train_test_split\n",
        "from cuml.feature_extraction.text import TfidfVectorizer\n",
        "from cuml.linear_model import LogisticRegression\n",
        "from cuml.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from cuml.pipeline import Pipeline\n",
        "import time\n",
        "\n",
        "print(\"Libraries (cuDF, cuML, CuPy) imported successfully.\")"
      ],
      "metadata": {
        "id": "9GE3Jvj8d3_M",
        "outputId": "8f45e1ff-8f7d-4096-b7dc-c1f22bff03a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries (cuDF, cuML, CuPy) imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3: Configuration (Mostly unchanged)\n",
        "\n",
        "DATASET_PATH = '/content/Hotel_Reviews.csv'\n",
        "\n",
        "NEGATIVE_REVIEW_COL = 'Negative_Review'\n",
        "POSITIVE_REVIEW_COL = 'Positive_Review'\n",
        "SCORE_COLUMN = 'Reviewer_Score'\n",
        "\n",
        "SENTIMENT_THRESHOLD = 5.0\n",
        "\n",
        "POSITIVE_LABEL = 'positive'\n",
        "NEGATIVE_LABEL = 'negative'\n",
        "\n",
        "sentiment_map = {NEGATIVE_LABEL: 0, POSITIVE_LABEL: 1}\n",
        "\n",
        "print(\"Configuration set:\")\n",
        "print(f\"  Dataset Path: {DATASET_PATH}\")\n",
        "print(f\"  Negative Review Column: {NEGATIVE_REVIEW_COL}\")\n",
        "print(f\"  Positive Review Column: {POSITIVE_REVIEW_COL}\")\n",
        "print(f\"  Score Column (for sentiment): {SCORE_COLUMN}\")\n",
        "print(f\"  Sentiment Threshold (Score > {SENTIMENT_THRESHOLD} is Positive): {SENTIMENT_THRESHOLD}\")\n",
        "print(f\"  Sentiment Map: {sentiment_map}\")"
      ],
      "metadata": {
        "id": "0LQc0jDgKkBu",
        "outputId": "7e766fe0-f125-4029-bc06-a75b414c5cf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration set:\n",
            "  Dataset Path: /content/Hotel_Reviews.csv\n",
            "  Negative Review Column: Negative_Review\n",
            "  Positive Review Column: Positive_Review\n",
            "  Score Column (for sentiment): Reviewer_Score\n",
            "  Sentiment Threshold (Score > 5.0 is Positive): 5.0\n",
            "  Sentiment Map: {'negative': 0, 'positive': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4: Load Data (Using cuDF)\n",
        "\n",
        "print(f\"Loading dataset from: {DATASET_PATH} using cuDF...\")\n",
        "columns_to_load = [NEGATIVE_REVIEW_COL, POSITIVE_REVIEW_COL, SCORE_COLUMN]\n",
        "\n",
        "try:\n",
        "    df = cudf.read_csv(DATASET_PATH, usecols=columns_to_load)\n",
        "    print(f\"Dataset loaded successfully using cuDF. Shape: {df.shape}\")\n",
        "    print(\"First 5 rows of loaded data:\")\n",
        "    print(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Dataset file not found at '{DATASET_PATH}'. Check path and upload status.\")\n",
        "    raise\n",
        "except ValueError as e:\n",
        "     print(f\"Error: Problem loading columns: {e}. \")\n",
        "     print(f\"Ensure CSV has columns: {columns_to_load} and check config in Cell 3.\")\n",
        "     raise\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred during loading: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "uWTiZer1KrwB",
        "outputId": "46d3f398-9573-48eb-cbae-e03c71de2891",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset from: /content/Hotel_Reviews.csv using cuDF...\n",
            "Dataset loaded successfully using cuDF. Shape: (515738, 3)\n",
            "First 5 rows of loaded data:\n",
            "                                     Negative_Review  \\\n",
            "0   I am so angry that i made this post available...   \n",
            "1                                        No Negative   \n",
            "2   Rooms are nice but for elderly a bit difficul...   \n",
            "3   My room was dirty and I was afraid to walk ba...   \n",
            "4   You When I booked with your company on line y...   \n",
            "\n",
            "                                     Positive_Review  Reviewer_Score  \n",
            "0   Only the park outside of the hotel was beauti...             2.9  \n",
            "1   No real complaints the hotel was great great ...             7.5  \n",
            "2   Location was good and staff were ok It is cut...             7.1  \n",
            "3   Great location in nice surroundings the bar a...             3.8  \n",
            "4    Amazing location and building Romantic setting              6.7  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 5: Preprocessing Data (Using cuDF - Text Cleaning CORRECTED)\n",
        "\n",
        "print(\"Preprocessing data using cuDF...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# --- Basic Checks and Cleaning ---\n",
        "# Drop rows where the score is missing\n",
        "df = df.dropna(subset=[SCORE_COLUMN]) # Use cuDF's dropna\n",
        "# Ensure review columns are strings before cleaning\n",
        "df[NEGATIVE_REVIEW_COL] = df[NEGATIVE_REVIEW_COL].astype(str)\n",
        "df[POSITIVE_REVIEW_COL] = df[POSITIVE_REVIEW_COL].astype(str)\n",
        "initial_rows = df.shape[0]\n",
        "print(f\"Initial rows after dropping NA scores: {initial_rows}\")\n",
        "\n",
        "# --- Text Cleaning Function (CORRECTED for GPU Compatibility) ---\n",
        "def clean_text_gpu(text_series):\n",
        "    # 1. Convert to lowercase first (handles potential NAs safely)\n",
        "    text_series = text_series.fillna('').str.lower()\n",
        "\n",
        "    # 2. Handle standard \"No Negative\"/\"No Positive\" (now case-sensitive on lowercase text)\n",
        "    # Use regex=False for faster fixed string replacement.\n",
        "    text_series = text_series.str.replace('no negative', '', regex=False)\n",
        "    text_series = text_series.str.replace('no positive', '', regex=False)\n",
        "\n",
        "    # 3. Remove punctuation and numbers using REGEX replace\n",
        "    # Keep only letters and spaces. Use .str.replace with regex=True.\n",
        "    text_series = text_series.str.replace(r'[^a-z\\s]', '', regex=True) # CORRECTED METHOD\n",
        "\n",
        "    # 4. Remove extra whitespace using REGEX replace, then strip\n",
        "    text_series = text_series.str.replace(r'\\s+', ' ', regex=True) # CORRECTED METHOD\n",
        "    text_series = text_series.str.strip()\n",
        "\n",
        "    # Optional: Fill any remaining NaNs potentially introduced\n",
        "    text_series = text_series.fillna('')\n",
        "    return text_series\n",
        "\n",
        "# --- Combine and Clean Text ---\n",
        "print(\"Cleaning and combining negative and positive review text...\")\n",
        "# Apply revised cleaning function to both review columns\n",
        "cleaned_neg = clean_text_gpu(df[NEGATIVE_REVIEW_COL])\n",
        "cleaned_pos = clean_text_gpu(df[POSITIVE_REVIEW_COL])\n",
        "\n",
        "# Combine cleaned positive and negative reviews\n",
        "# Add a space in between only if both parts have content\n",
        "df['cleaned_text'] = cleaned_neg + ' ' + cleaned_pos\n",
        "df['cleaned_text'] = df['cleaned_text'].str.strip() # Remove leading/trailing spaces from combine\n",
        "print(\"Text combination and cleaning done.\")\n",
        "\n",
        "# --- Create Sentiment Labels from Score ---\n",
        "print(f\"Creating sentiment labels based on '{SCORE_COLUMN}' > {SENTIMENT_THRESHOLD}...\")\n",
        "# Ensure score column is numeric first\n",
        "df[SCORE_COLUMN] = df[SCORE_COLUMN].astype('float32')\n",
        "# Apply threshold (cuDF is efficient with numeric/boolean ops)\n",
        "df['sentiment_numeric'] = (df[SCORE_COLUMN] > SENTIMENT_THRESHOLD).astype('int32')\n",
        "print(\"Sentiment label creation done.\")\n",
        "\n",
        "# --- Final Cleanup ---\n",
        "# Remove rows where the combined text is empty after cleaning\n",
        "df = df[df['cleaned_text'].str.len() > 0]\n",
        "rows_after_empty_text_drop = df.shape[0]\n",
        "print(f\"Removed {initial_rows - rows_after_empty_text_drop} rows with empty/NA text or scores during preprocessing.\") # Adjusted count message\n",
        "\n",
        "processed_rows = df.shape[0]\n",
        "print(f\"\\nPreprocessing finished. Rows remaining for analysis: {processed_rows}\")\n",
        "print(f\"Time taken for preprocessing: {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "# --- Checks and Final Output ---\n",
        "if processed_rows < 50:\n",
        "    print(f\"\\nWarning: Only {processed_rows} rows remaining after preprocessing.\")\n",
        "    if processed_rows == 0:\n",
        "      print(\"Error: No data remaining.\")\n",
        "      raise SystemExit(\"Stopping due to no data.\")\n",
        "\n",
        "print(f\"\\nValue counts for derived sentiment (0={NEGATIVE_LABEL}, 1={POSITIVE_LABEL} based on score > {SENTIMENT_THRESHOLD}):\")\n",
        "try:\n",
        "    # value_counts returns a cuDF Series\n",
        "    print(df['sentiment_numeric'].value_counts())\n",
        "except Exception as e:\n",
        "    print(f\"Could not get value counts: {e}\")\n",
        "\n",
        "print(\"\\nSample of combined cleaned text, original score, and derived sentiment:\")\n",
        "try:\n",
        "    print(df[['cleaned_text', SCORE_COLUMN, 'sentiment_numeric']].head())\n",
        "except Exception as e:\n",
        "    print(f\"Could not display head(): {e}\")\n",
        "\n",
        "# Optional: Clean up intermediate GPU memory\n",
        "# del cleaned_neg, cleaned_pos\n",
        "# import gc; gc.collect()"
      ],
      "metadata": {
        "id": "95bRWbO8Ktwn",
        "outputId": "2e17555d-ec86-457a-b0cd-726ea57886e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing data using cuDF...\n",
            "Initial rows after dropping NA scores: 101465\n",
            "Cleaning and combining negative and positive review text...\n",
            "Text combination and cleaning done.\n",
            "Creating sentiment labels based on 'Reviewer_Score' > 5.0...\n",
            "Sentiment label creation done.\n",
            "Removed 44 rows with empty/NA text or scores during preprocessing.\n",
            "\n",
            "Preprocessing finished. Rows remaining for analysis: 101421\n",
            "Time taken for preprocessing: 0.60 seconds\n",
            "\n",
            "Value counts for derived sentiment (0=negative, 1=positive based on score > 5.0):\n",
            "sentiment_numeric\n",
            "1    95107\n",
            "0     6314\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample of combined cleaned text, original score, and derived sentiment:\n",
            "                                        cleaned_text  Reviewer_Score  \\\n",
            "0  i am so angry that i made this post available ...             2.9   \n",
            "1  no real complaints the hotel was great great l...             7.5   \n",
            "2  rooms are nice but for elderly a bit difficult...             7.1   \n",
            "3  my room was dirty and i was afraid to walk bar...             3.8   \n",
            "4  you when i booked with your company on line yo...             6.7   \n",
            "\n",
            "   sentiment_numeric  \n",
            "0                  0  \n",
            "1                  1  \n",
            "2                  1  \n",
            "3                  0  \n",
            "4                  1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 6: Split Data into Training and Testing Sets (Revised - Index Splitting)\n",
        "import cudf\n",
        "import cupy as cp\n",
        "from cuml.model_selection import train_test_split # Ensure this import is present\n",
        "\n",
        "print(\"Splitting data into training and testing sets using cuML (via index splitting)...\")\n",
        "\n",
        "# Make sure df exists and is not empty (check assumes df is in locals scope from Cell 5)\n",
        "if 'df' not in locals() or df.empty:\n",
        "    print(\"Error: Cannot split data - DataFrame 'df' is not available or empty.\")\n",
        "    # Depending on your flow, you might want to raise an error here\n",
        "    # raise ValueError(\"DataFrame 'df' is missing or empty before splitting.\")\n",
        "else:\n",
        "    # Define features (X) and target (y) as cuDF Series\n",
        "    X = df['cleaned_text']\n",
        "    y = df['sentiment_numeric']\n",
        "\n",
        "    # 1. Create a CuPy array of numerical indices for the DataFrame\n",
        "    num_rows = df.shape[0]\n",
        "    indices = cp.arange(num_rows) # CuPy array [0, 1, 2, ..., n-1]\n",
        "\n",
        "    # 2. Convert the target Series 'y' to a CuPy array for stratification\n",
        "    # Stratify function usually expects numerical arrays\n",
        "    try:\n",
        "        y_cupy = y.to_cupy()\n",
        "        print(f\"Target 'y' converted to CuPy array for stratification. Shape: {y_cupy.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting target 'y' to CuPy array: {e}\")\n",
        "        print(\"Ensure 'y' (sentiment_numeric) is a numeric type in the DataFrame.\")\n",
        "        raise\n",
        "\n",
        "    print(f\"Splitting {len(indices)} indices based on target labels...\")\n",
        "    try:\n",
        "        # 3. Split the NUMERICAL INDICES, stratifying by the CuPy target array\n",
        "        train_idx_cp, test_idx_cp = train_test_split(\n",
        "            indices,              # Split the indices array\n",
        "            test_size=0.25,       # Use 25% of data for testing\n",
        "            random_state=42,      # For reproducibility\n",
        "            stratify=y_cupy,      # Stratify using the CuPy version of y\n",
        "            shuffle=True          # Shuffle indices before splitting\n",
        "        )\n",
        "        print(f\"Indices split successfully. Train indices: {len(train_idx_cp)}, Test indices: {len(test_idx_cp)}\")\n",
        "\n",
        "        # 4. Use the split indices to select data from the original cuDF Series\n",
        "        # cuDF's .iloc usually accepts CuPy arrays or cuDF integer Series/Indices directly\n",
        "        X_train = X.iloc[train_idx_cp]\n",
        "        X_test = X.iloc[test_idx_cp]\n",
        "        y_train = y.iloc[train_idx_cp]\n",
        "        y_test = y.iloc[test_idx_cp]\n",
        "\n",
        "        print(f\"\\nTraining set size: {len(X_train)}\")\n",
        "        print(f\"Testing set size: {len(X_test)}\")\n",
        "        # Optional: Check types to confirm they are cuDF Series\n",
        "        # print(f\"X_train type: {type(X_train)}\")\n",
        "        # print(f\"y_train type: {type(y_train)}\")\n",
        "\n",
        "    except ValueError as ve:\n",
        "         # Catch potential errors even during index splitting\n",
        "         print(f\"\\nValueError during index splitting or data selection: {ve}\")\n",
        "         raise\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn unexpected error occurred during splitting: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "kBBTHjLHKv0d",
        "outputId": "eb1a445c-35d0-411f-9f3e-f9efd1360459",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting data into training and testing sets using cuML (via index splitting)...\n",
            "Target 'y' converted to CuPy array for stratification. Shape: (101421,)\n",
            "Splitting 101421 indices based on target labels...\n",
            "Indices split successfully. Train indices: 76066, Test indices: 25355\n",
            "\n",
            "Training set size: 76066\n",
            "Testing set size: 25355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 7: Create TF-IDF and Model Pipeline (Using cuML)\n",
        "print(\"Setting up cuML TF-IDF Vectorizer and Logistic Regression model...\")\n",
        "\n",
        "# cuML's TfidfVectorizer (API is very similar to sklearn's)\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=20000,\n",
        "    stop_words='english'\n",
        "    # cuML's TF-IDF might default to different norms or parameters, check docs if needed\n",
        ")\n",
        "\n",
        "# cuML's Logistic Regression\n",
        "# Check cuML documentation for exact parameter equivalence and availability (e.g., 'class_weight')\n",
        "# As of recent versions, class_weight='balanced' IS often supported.\n",
        "logistic_regression_model = LogisticRegression(\n",
        "    # cuML's LogReg might have different default solvers or parameters.\n",
        "    # It often uses highly optimized solvers like OWL-QN.\n",
        "    penalty='l2', # Common default\n",
        "    C=1.0,        # Regularization strength\n",
        "    random_state=42,\n",
        "    class_weight='balanced', # TRY THIS - Check if supported in your cuML version\n",
        "    max_iter=500 # Adjust max_iter if needed\n",
        ")\n",
        "\n",
        "# Use cuML's Pipeline\n",
        "model_pipeline = Pipeline([\n",
        "    ('tfidf', tfidf_vectorizer),\n",
        "    ('clf', logistic_regression_model)\n",
        "])\n",
        "\n",
        "print(\"cuML Pipeline created successfully.\")\n",
        "# print(model_pipeline) # Optional: print pipeline structure"
      ],
      "metadata": {
        "id": "ozPFo7xIKygJ",
        "outputId": "e98906f6-7cb1-4d77-d030-b58c91ec0263",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up cuML TF-IDF Vectorizer and Logistic Regression model...\n",
            "[2025-04-14 16:46:36.568] [CUML] [info] Unused keyword parameter: random_state during cuML estimator initialization\n",
            "cuML Pipeline created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 8: Train the Model (Using cuML Pipeline)\n",
        "print(\"Training the cuML model pipeline...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Check if training data exists (should be cuDF Series)\n",
        "if 'X_train' in locals() and not X_train.empty:\n",
        "    # .fit() trains the whole cuML pipeline on GPU data\n",
        "    model_pipeline.fit(X_train, y_train)\n",
        "    print(f\"Model training completed.\")\n",
        "    print(f\"Time taken for training: {time.time() - start_time:.2f} seconds\")\n",
        "else:\n",
        "    print(\"Error: Training data (X_train cuDF Series) is not available or empty.\")"
      ],
      "metadata": {
        "id": "NNe4kKDOK0kT",
        "outputId": "b130ba7b-eff5-4df4-faee-0f3d59540fb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the cuML model pipeline...\n",
            "Model training completed.\n",
            "Time taken for training: 6.92 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 9: Evaluate the Model (Using cuML Metrics / Sklearn Report)\n",
        "print(\"Evaluating the model on the test set...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Check if model and test data exist\n",
        "if 'model_pipeline' in locals() and 'X_test' in locals() and not X_test.empty:\n",
        "    try:\n",
        "      # Predict using the cuML pipeline (output is typically CuPy array or cuDF Series)\n",
        "      y_pred = model_pipeline.predict(X_test)\n",
        "\n",
        "      # Ensure y_test and y_pred are compatible for metrics (e.g., cupy arrays)\n",
        "      # Convert if necessary, though cuML metrics often handle cuDF/CuPy directly\n",
        "      # y_test_cp = cp.asarray(y_test.values) # Example conversion if needed\n",
        "      # y_pred_cp = cp.asarray(y_pred)       # Example conversion if needed\n",
        "\n",
        "      # Use cuML's accuracy score\n",
        "      accuracy = accuracy_score(y_test, y_pred) # Pass cuDF Series directly\n",
        "\n",
        "      print(f\"Evaluation completed.\")\n",
        "      print(f\"Time taken for evaluation: {time.time() - start_time:.2f} seconds\")\n",
        "      print(\"\\n--- Evaluation Results ---\")\n",
        "      print(f\"Accuracy (cuML): {accuracy:.4f}\")\n",
        "\n",
        "      # For the detailed classification report, pull data to CPU and use sklearn's\n",
        "      print(\"\\nCalculating Classification Report (requires data transfer to CPU)...\")\n",
        "      y_test_cpu = y_test.get() # Get as numpy array on CPU\n",
        "      y_pred_cpu = y_pred.get() # Get as numpy array on CPU (if cupy) or y_pred.to_numpy() if cuDF Series\n",
        "\n",
        "      report = classification_report(y_test_cpu, y_pred_cpu, target_names=[NEGATIVE_LABEL, POSITIVE_LABEL])\n",
        "      print(\"\\nClassification Report (sklearn on CPU data):\")\n",
        "      print(report)\n",
        "      print(\"------------------------\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during evaluation: {e}\")\n",
        "        # Consider adding more specific error handling for cuML/CuPy issues\n",
        "        # import traceback\n",
        "        # traceback.print_exc()\n",
        "else:\n",
        "    print(\"Error: Model or test data is not available. Cannot evaluate.\")"
      ],
      "metadata": {
        "id": "2oJ1y1lTK23W",
        "outputId": "d66d6c94-4037-4a1f-e568-de3d97abeaae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the model on the test set...\n",
            "Evaluation completed.\n",
            "Time taken for evaluation: 0.53 seconds\n",
            "\n",
            "--- Evaluation Results ---\n",
            "Accuracy (cuML): 0.8715\n",
            "\n",
            "Calculating Classification Report (requires data transfer to CPU)...\n",
            "An error occurred during evaluation: 'Series' object has no attribute 'get'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 10: Example Prediction on New Data (Using cuML Pipeline)\n",
        "print(\"\\n--- Example Prediction ---\")\n",
        "\n",
        "# New reviews as a standard Python list\n",
        "new_reviews_list = [\n",
        "    \"The room was the worst experience\",\n",
        "    \"Absolutely fantastic stay, loved the service and the clean room!\",\n",
        "    \"It was okay, nothing special but not bad either.\"\n",
        "]\n",
        "\n",
        "# Check if model pipeline exists\n",
        "if 'model_pipeline' in locals() and 'sentiment_map' in locals():\n",
        "    try:\n",
        "        # 1. Convert Python list to cuDF Series for GPU processing\n",
        "        new_reviews_cudf = cudf.Series(new_reviews_list)\n",
        "\n",
        "        # 2. Use the trained cuML pipeline to predict\n",
        "        # Output is typically a CuPy array\n",
        "        new_predictions_numeric_gpu = model_pipeline.predict(new_reviews_cudf)\n",
        "        new_predictions_proba_gpu = model_pipeline.predict_proba(new_reviews_cudf)\n",
        "\n",
        "        # 3. Transfer predictions back to CPU (NumPy arrays) for printing/mapping\n",
        "        new_predictions_numeric = cp.asnumpy(new_predictions_numeric_gpu)\n",
        "        new_predictions_proba = cp.asnumpy(new_predictions_proba_gpu)\n",
        "\n",
        "        # 4. Map numeric predictions back to labels (same logic as before)\n",
        "        label_map_rev = {v: k for k, v in sentiment_map.items()} # Reverse map {0: 'negative', 1: 'positive'}\n",
        "\n",
        "        print(\"Prediction Results:\")\n",
        "        for i, review in enumerate(new_reviews_list): # Iterate through original list\n",
        "            pred_label = label_map_rev[new_predictions_numeric[i]]\n",
        "            neg_prob = new_predictions_proba[i][0] # Probability of class 0 (negative)\n",
        "            pos_prob = new_predictions_proba[i][1] # Probability of class 1 (positive)\n",
        "            print(f\"\\nReview: \\\"{review}\\\"\")\n",
        "            print(f\"Predicted Sentiment: {pred_label}\")\n",
        "            print(f\"Probabilities -> {NEGATIVE_LABEL}: {neg_prob:.4f}, {POSITIVE_LABEL}: {pos_prob:.4f}\")\n",
        "        print(\"------------------------\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during example prediction: {e}\")\n",
        "        # import traceback\n",
        "        # traceback.print_exc()\n",
        "else:\n",
        "    print(\"Error: Model pipeline or sentiment map not available for prediction.\")"
      ],
      "metadata": {
        "id": "K7I0efyCK4ev",
        "outputId": "8a347cab-3656-4d9e-a74c-f57e2420afa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Example Prediction ---\n",
            "Prediction Results:\n",
            "\n",
            "Review: \"The room was the worst experience\"\n",
            "Predicted Sentiment: negative\n",
            "Probabilities -> negative: 0.9630, positive: 0.0370\n",
            "\n",
            "Review: \"Absolutely fantastic stay, loved the service and the clean room!\"\n",
            "Predicted Sentiment: positive\n",
            "Probabilities -> negative: 0.0303, positive: 0.9697\n",
            "\n",
            "Review: \"It was okay, nothing special but not bad either.\"\n",
            "Predicted Sentiment: negative\n",
            "Probabilities -> negative: 0.8825, positive: 0.1175\n",
            "------------------------\n"
          ]
        }
      ]
    }
  ]
}